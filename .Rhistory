y = c(rep(1, 36), rep(0, 198)) # leukemia cases
x = c(rep(1, 3), rep(0, 33), rep(1, 5), rep(0, 193)) # exposure
#helper functions
expit <- function(mu) 1/(1+exp(-mu))
loglik = function(y,x,beta){
# calculate the log likelihood
lli = dbinom(y, 1, expit(beta[1] + x*beta[2]), log=TRUE)
sum(lli)
}
riskdifference = function(y,x,beta){
# baseline odds (offset)
# calculate a risk difference
poprisk = 4.8/100000
popodds = poprisk/(1-poprisk)
studyodds = mean(y)/(1-mean(y))
r1 = expit(log(popodds/studyodds) + beta[1] + beta[2])
r0 = expit(log(popodds/studyodds) + beta[1])
mean(r1-r0)
}
# data se utiliza para ajustar un modelo de regresión logística binaria
data = data.frame(leuk=y, magfield=x)
# Ajuste del modelo de regresión logística, para predecir la relacion de las variables
# indicar que se trata de un modelo binomial
mod = glm(leuk ~ magfield, family=binomial(), data=data)
# Resumen del modelo y extracción de coeficientes:
summary(mod)$coefficients
beta1 = summary(mod)$coefficients[2,1]
se1 = summary(mod)$coefficients[2,2]
cat("\n\nMaximum likelihood beta coefficient (95% CI)\n")
round(c(beta=beta1, ll=beta1+se1*qnorm(0.025), ul=beta1+se1*qnorm(0.975)), 2)
cat("\n\nMaximum likelihood odds ratio (95% CI)\n")
round(exp(c(beta=beta1, ll=beta1+se1*qnorm(0.025), ul=beta1+se1*qnorm(0.975))), 2)
cat("\n\nMaximum likelihood risk difference (multiplied by 1000) \n")
round(c(rd_1000=riskdifference(y,x,mod$coefficients)*1000), 2)
summary(mod)$coefficients
beta1 = summary(mod)$coefficients[2,1]
beta1
se1 = summary(mod)$coefficients[2,2]
se1
cat("\n\nMaximum likelihood beta coefficient (95% CI)\n")
round(c(beta=beta1, ll=beta1+se1*qnorm(0.025), ul=beta1+se1*qnorm(0.975)), 2)
# Resumen del modelo y extracción de coeficientes:
summary(mod)$coefficients
plot(beta_post, pch=19, col=rgb(0,0,0,0.05), xlab=expression(beta[0]), ylab=expression(beta[1]), xlim=c(-2.5,2.5), ylim=c(-4.5,4.5))
# initialize
M=10000  # Numero de muestras que se generarán en el algoritmo
set.seed(91828) # Semilla para inicializar el generador de números aleatorios.
beta_post = matrix(nrow=M, ncol=2) # Matriz para almacenar coeficientes del modelo
colnames(beta_post) = c('beta0', 'beta1') # Se asgina nombres a las dos columnas
accept = numeric(M) # vector númerico con M muestras
rd = numeric(M) # vector númerico con M muestras
beta_post[1,] = c(2,-3) # se establece la primera fila con valores iniciales (2, -3)
rd[1] = riskdifference(y, x, beta_post[1,]) # dif. de riesgo de las estimaciones
accept[1] = 1 # Vector para registrar si la muestra es aceptada (1) o rechazada (0)
for(i in 2:M){
oldb = beta_post[i-1,] # almacena coeficiente de la muestra anterior
prop = rnorm(2, sd=0.2) # Genera una muestra para nuevos coeficientes
newb = oldb+prop # Calcula los nuevos coeficientes al sumar la propuesta
num = loglik(y,x,newb) # Calculan el logaritmo de verosimilitud para newb
den = loglik(y,x,oldb) # Calculan el logaritmo de verosimilitud para oldb
acceptprob = exp(num-den) # calcula la /p de aceptar la nueva muestra
acc = (acceptprob > runif(1)) # aceptar o rechazar la nueva función anterior
if(acc){
beta_post[i,] = newb # se almacenan si es aceptada
accept[i] = 1
}else{
beta_post[i,] = oldb
accept[i] = 0
}
# Calcula y almacena la diferencia de riesgo para cada conjunto de estimaciones
rd[i] = 1000*riskdifference(y, x, beta_post[i,])
}
mean(accept)
summary(beta_post)
init = beta_post[1,]
postmean = apply(beta_post[-c(1:1000),], 2, mean)
cat("Posterior mean\n", round(postmean, 2))
plot(beta_post, pch=19, col=rgb(0,0,0,0.05), xlab=expression(beta[0]), ylab=expression(beta[1]), xlim=c(-2.5,2.5), ylim=c(-4.5,4.5))
points(init[1], init[2], col="red", pch=19)
points(postmean[1], postmean[2], col="orange", pch=19)
legend("topright", col=c("red", "orange"), legend=c("Initial value", "Post. mean"), pch=19)
plot(beta_post, pch=19, col=rgb(0,0,0,0.05), xlab=expression(beta[0]), ylab=expression(beta[1]), xlim=c(-2.5,2.5), ylim=c(-4.5,4.5))
points(init[1], init[2], col="deepskyblue2", pch=19)
points(postmean[1], postmean[2], col="darkorchid4", pch=19)
legend("topright", col=c("deepskyblue2", "darkorchid4"), legend=c("Initial value", "Post. mean"), pch=19)
plot(beta_post, pch=19, col=rgb(0,0,0,0.05), xlab=expression(beta[0]), ylab=expression(beta[1]), xlim=c(-2.5,2.5), ylim=c(-4.5,4.5))
points(init[1], init[2], col="deepskyblue2", pch=19)
points(postmean[1], postmean[2], col="seagreen1", pch=19)
legend("topright", col=c("deepskyblue2", "seagreen1"), legend=c("Initial value", "Post. mean"), pch=19)
col1 = rgb(0,0,0,.5)
col2 = rgb(1,0,0,.35)
par(mfcol=c(1,2))
#trace plots
plot(beta_post[1:200,2], type='l',  ylab=expression(beta[1]), xlab="Iteration", ylim=c(-4, 4), col=col1)
lines(beta_post_guide[1:200,2], col=col2)
# initialize
M=10000 # Numero de muestras que se generarán en el algoritmo
set.seed(91828) # Semilla para inicializar el generador de números aleatorios
beta_post_guide = matrix(nrow=M, ncol=2) # Matriz para almacenar coeficientes del modelo
colnames(beta_post_guide) = c('beta0', 'beta1') # Se asgina nombres a las dos columnas
accept = numeric(M) # vector númerico con M muestra
rd_guide = numeric(M) # vector númerico con M muestra
beta_post_guide[1,] = c(2,-3)  # se establece la primera fila con valores iniciales (2, -3)
rd_guide[1] = riskdifference(y,x,beta_post_guide[1,]) # dif. de riesgo de las estimaciones
accept[1] = 1 # Vector para registrar si la muestra es aceptada (1) o rechazada (0)
dir = 1 # Esta variable se utiliza para controlar la dirección de exploración
for(i in 2:M){
oldb = beta_post_guide[i-1,] # almacena los coeficientes de la muestra anterior
prop = dir*abs(rnorm(2, sd=0.2)) # muestra para nuevos coeficientes multiplicando por dir
newb = oldb+prop # Calcula los nuevos coeficientes al sumar la propuesta
num = loglik(y,x,newb) # Calculan el logaritmo de verosimilitud para newb
den = loglik(y,x,oldb) # Calculan el logaritmo de verosimilitud para oldb
acceptprob = exp(num-den) # calcula la /p de aceptar la nueva muestra
acc = (acceptprob > runif(1)) # aceptar o rechazar la nueva función anterior
if(acc){
beta_post_guide[i,] = newb
accept[i] = 1
}else{
beta_post_guide[i,] = oldb
accept[i] = 0 # si la muestra es rechazada (acc == 0)
dir = dir*-1 # se invierte la dirección dir multiplicándola por -1.
# cambia la dirección de exploración en el espacio de parámetros.
}
# Calcula y almacena la diferencia de riesgo para cada conjunto de estimaciones
rd_guide[i] = 1000*riskdifference(y,x,beta_post_guide[i,])
}
# se calcula el valor del posterior promedio de los coeficientes
# para las muestras posteriores a las primeras 1000
postmean = apply(beta_post_guide[-c(1:1000),], 2, mean)
cat("Posterior mean, guided\n", round(postmean, 2))
col1 = rgb(0,0,0,.5)
col2 = rgb(1,0,0,.35)
par(mfcol=c(1,2))
#trace plots
plot(beta_post[1:200,2], type='l',  ylab=expression(beta[1]), xlab="Iteration", ylim=c(-4, 4), col=col1)
lines(beta_post_guide[1:200,2], col=col2)
legend("topright", lty=1, col=c(col1, col2), legend=c("Rand. walk", "Guided"))
plot(9800:10000, beta_post[9800:10000,2], type='l',  ylab=expression(beta[1]), xlab="Iteration", ylim=c(-4, 4), col=col1)
lines(9800:10000, beta_post_guide[9800:10000,2], col=col2)
legend("topright", lty=1, col=c(col1, col2), legend=c("Rand. walk", "Guided"))
